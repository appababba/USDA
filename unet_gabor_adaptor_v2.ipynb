{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyME6h1jRBvbx7sOSC+DMnlI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appababba/USDA/blob/main/unet_gabor_adaptor_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install segmentation-models-pytorch==0.3.3 albumentations==1.4.7 --no-deps\n",
        "import os, random, shutil, math, json, csv, glob, hashlib\n",
        "from datetime import datetime\n",
        "from glob import glob as gglob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import segmentation_models_pytorch as smp\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "\n",
        "CFG = {\n",
        "    \"RUN\": dict(\n",
        "        DO_BASELINE=True,\n",
        "        DO_LOVASZ=False,\n",
        "        DO_ADAPTER_VARIANT=True,\n",
        "        SAVE_SAMPLES=24\n",
        "    ),\n",
        "    \"GABOR\": dict(\n",
        "        enabled=True,\n",
        "        mode=\"concat\",\n",
        "        learnable=False,\n",
        "        kernel_size=15,\n",
        "        orientations=8,\n",
        "        wavelengths=[6, 10, 16],\n",
        "        sigmas=[3.0, 5.0, 7.0],\n",
        "        gamma=0.5,\n",
        "        phases=[0.0, math.pi/2],\n",
        "        magnitude=True\n",
        "    ),\n",
        "    \"TRAIN\": dict(\n",
        "        img_size=(256, 256),\n",
        "        batch_size=8,\n",
        "        epochs=15,\n",
        "        adapter_epochs=20,\n",
        "        lr=1e-4,\n",
        "        weight_decay=1e-4,\n",
        "        pos_weight=9.66,\n",
        "        random_seed=42\n",
        "    ),\n",
        "    \"PATHS\": dict(\n",
        "        base_drive=\"/content/drive/Shared drives/USDA-Summer2025\",\n",
        "        data=\"data\",\n",
        "        images=\"Exported_Images\",\n",
        "        masks=\"Exported_Masks\",\n",
        "        models=\"models\",\n",
        "        exports=\"exports\"\n",
        "    )\n",
        "}\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "SEED = CFG[\"TRAIN\"][\"random_seed\"]\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "BASE_DRIVE = CFG[\"PATHS\"][\"base_drive\"]\n",
        "DATA_DIR   = os.path.join(BASE_DRIVE, CFG[\"PATHS\"][\"data\"])\n",
        "IMG_DRIVE  = os.path.join(DATA_DIR, CFG[\"PATHS\"][\"images\"])\n",
        "MSK_DRIVE  = os.path.join(DATA_DIR, CFG[\"PATHS\"][\"masks\"])\n",
        "MODELS_DIR = os.path.join(BASE_DRIVE, CFG[\"PATHS\"][\"models\"])\n",
        "EXPORTS_DIR= os.path.join(BASE_DRIVE, CFG[\"PATHS\"][\"exports\"])\n",
        "os.makedirs(MODELS_DIR, exist_ok=True); os.makedirs(EXPORTS_DIR, exist_ok=True)\n",
        "\n",
        "LOCAL_ROOT = \"/content/local_data\"\n",
        "IMG_LOCAL  = os.path.join(LOCAL_ROOT, CFG[\"PATHS\"][\"images\"])\n",
        "MSK_LOCAL  = os.path.join(LOCAL_ROOT, CFG[\"PATHS\"][\"masks\"])\n",
        "\n",
        "def ensure_local(src, dst):\n",
        "    if os.path.isdir(dst) and any(True for _ in os.scandir(dst)):\n",
        "        print(f\"ðŸ“¦ Using existing local: {dst}\"); return\n",
        "    print(f\"ðŸ“¥ Copying {src} -> {dst}\")\n",
        "    os.makedirs(dst, exist_ok=True)\n",
        "    for root,_,files in os.walk(src):\n",
        "        rel = os.path.relpath(root, src)\n",
        "        out = os.path.join(dst, rel) if rel!=\".\" else dst\n",
        "        os.makedirs(out, exist_ok=True)\n",
        "        for f in files:\n",
        "            sp, dp = os.path.join(root,f), os.path.join(out,f)\n",
        "            if not os.path.exists(dp):\n",
        "                shutil.copy2(sp, dp)\n",
        "    print(\"âœ… Copy done.\")\n",
        "\n",
        "ensure_local(IMG_DRIVE, IMG_LOCAL)\n",
        "ensure_local(MSK_DRIVE, MSK_LOCAL)\n",
        "\n",
        "class SegDataset(Dataset):\n",
        "    def __init__(self, image_paths, mask_dir, size=(256,256), transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_dir = mask_dir\n",
        "        self.size = size\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.image_paths)\n",
        "\n",
        "    def _mask_path_for(self, img_path):\n",
        "        base = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        p1 = os.path.join(self.mask_dir, f\"{base}_mask.png\")\n",
        "        if os.path.exists(p1): return p1\n",
        "        for ext in ('.png','.jpg','.jpeg','.tif','.tiff'):\n",
        "            p2 = os.path.join(self.mask_dir, base+ext)\n",
        "            if os.path.exists(p2): return p2\n",
        "        raise FileNotFoundError(f\"No mask for {img_path}\")\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ip = self.image_paths[idx]\n",
        "        mp = self._mask_path_for(ip)\n",
        "        img = cv2.cvtColor(cv2.imread(ip), cv2.COLOR_BGR2RGB)\n",
        "        msk = cv2.imread(mp, cv2.IMREAD_GRAYSCALE)\n",
        "        msk = (msk > 0).astype(np.uint8)\n",
        "\n",
        "        if self.transform:\n",
        "            out = self.transform(image=img, mask=msk)\n",
        "            img, msk = out[\"image\"], out[\"mask\"]\n",
        "        else:\n",
        "            img = cv2.resize(img, self.size, interpolation=cv2.INTER_LINEAR).astype(np.float32)/255.0\n",
        "            msk = cv2.resize(msk, self.size, interpolation=cv2.INTER_NEAREST)\n",
        "            img = torch.from_numpy(img).permute(2,0,1).float()\n",
        "            msk = torch.from_numpy(msk).unsqueeze(0).float()\n",
        "\n",
        "        if isinstance(msk, torch.Tensor) and msk.ndim==2:\n",
        "            msk = msk.unsqueeze(0)\n",
        "        return img, msk.float()\n",
        "\n",
        "class GaborStem(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        k = cfg[\"kernel_size\"]; assert k % 2 == 1, \"kernel_size must be odd\"\n",
        "        self.k = k; self.gamma = cfg[\"gamma\"]; self.magnitude = cfg[\"magnitude\"]; self.learnable = cfg[\"learnable\"]\n",
        "\n",
        "        ax = torch.arange(-(k//2), k//2 + 1).float()\n",
        "        X, Y = torch.meshgrid(ax, ax, indexing='xy')\n",
        "        self.register_buffer('X', X); self.register_buffer('Y', Y)\n",
        "\n",
        "        self.orientations = cfg[\"orientations\"]\n",
        "        phases = torch.tensor(cfg[\"phases\"], dtype=torch.float32)\n",
        "        self.register_buffer('phases_buf', phases)\n",
        "\n",
        "        lambdas = torch.tensor(cfg[\"wavelengths\"], dtype=torch.float32)\n",
        "        sigmas  = torch.tensor(cfg[\"sigmas\"], dtype=torch.float32)\n",
        "        if sigmas.ndim==0: sigmas = sigmas.repeat(lambdas.numel())\n",
        "        assert lambdas.numel()==sigmas.numel(), \"wavelengths and sigmas must align\"\n",
        "\n",
        "        thetas = torch.linspace(0, math.pi, steps=self.orientations, dtype=torch.float32)\n",
        "        base = []\n",
        "        for lam, sig in zip(lambdas, sigmas):\n",
        "            for th in thetas:\n",
        "                for ph in phases:\n",
        "                    base.append((th.item(), sig.item(), lam.item(), ph.item()))\n",
        "        base = torch.tensor(base, dtype=torch.float32)\n",
        "\n",
        "        if self.learnable: self.params = nn.Parameter(base)\n",
        "        else: self.register_buffer('params_buf', base)\n",
        "\n",
        "        self.num_per_phase = lambdas.numel() * self.orientations\n",
        "        self.out_channels = self.num_per_phase if (self.magnitude and len(phases)==2) else base.shape[0]\n",
        "        self.norm = nn.InstanceNorm2d(self.out_channels, affine=False)\n",
        "\n",
        "    def _kernels(self, device, dtype):\n",
        "        P = self.params if self.learnable else self.params_buf\n",
        "        P = P.to(device=device, dtype=dtype)\n",
        "        X = self.X.to(device=device, dtype=dtype); Y = self.Y.to(device=device, dtype=dtype)\n",
        "        gamma = torch.as_tensor(self.gamma, dtype=dtype, device=device)\n",
        "\n",
        "        theta = P[:,0].view(-1,1,1); sigma = P[:,1].view(-1,1,1)\n",
        "        lambd = P[:,2].view(-1,1,1); phase = P[:,3].view(-1,1,1)\n",
        "\n",
        "        Xp =  X*torch.cos(theta) + Y*torch.sin(theta)\n",
        "        Yp = -X*torch.sin(theta) + Y*torch.cos(theta)\n",
        "\n",
        "        gauss = torch.exp(-(Xp**2 + (gamma*Yp)**2) / (2*sigma**2))\n",
        "        carrier = torch.cos(2*math.pi*Xp / lambd + phase)\n",
        "        g = gauss * carrier\n",
        "\n",
        "        g = g - g.mean(dim=(1,2), keepdim=True)\n",
        "        g = g / (g.square().sum(dim=(1,2), keepdim=True).sqrt() + 1e-8)\n",
        "        return g\n",
        "\n",
        "    def forward(self, x):\n",
        "        device, dtype = x.device, x.dtype\n",
        "        y = 0.299*x[:,0:1] + 0.587*x[:,1:2] + 0.114*x[:,2:3]\n",
        "        K = self._kernels(device, dtype)\n",
        "        if self.magnitude and self.phases_buf.numel()==2:\n",
        "            N = self.num_per_phase\n",
        "            k_cos = K[0::2].unsqueeze(1); k_sin = K[1::2].unsqueeze(1)\n",
        "            rc = torch.conv2d(y, k_cos, padding=self.k//2)\n",
        "            rs = torch.conv2d(y, k_sin, padding=self.k//2)\n",
        "            feats = torch.sqrt(rc**2 + rs**2 + 1e-8)\n",
        "        else:\n",
        "            feats = torch.conv2d(y, K.unsqueeze(1), padding=self.k//2)\n",
        "        return self.norm(feats)\n",
        "\n",
        "class UNetWithGabor(nn.Module):\n",
        "    def __init__(self, gcfg, in_img_ch=3):\n",
        "        super().__init__()\n",
        "        self.use_gabor = gcfg[\"enabled\"]\n",
        "        if self.use_gabor:\n",
        "            self.gabor = GaborStem(gcfg)\n",
        "            in_ch = in_img_ch + self.gabor.out_channels if gcfg[\"mode\"]==\"concat\" else self.gabor.out_channels\n",
        "        else:\n",
        "            in_ch = in_img_ch\n",
        "        encoder_weights = 'imagenet' if in_ch == 3 else None\n",
        "        self.net = smp.Unet(encoder_name='resnet50', encoder_weights=encoder_weights,\n",
        "                            in_channels=in_ch, classes=1, activation=None)\n",
        "        self.mode = gcfg[\"mode\"]\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_gabor:\n",
        "            g = self.gabor(x)\n",
        "            x = torch.cat([x, g], dim=1) if self.mode==\"concat\" else g\n",
        "        return self.net(x)\n",
        "\n",
        "class UNetWithGabor_Adapted(nn.Module):\n",
        "    def __init__(self, gcfg, in_img_ch=3):\n",
        "        super().__init__()\n",
        "        self.use_gabor = gcfg[\"enabled\"]; self.mode = gcfg[\"mode\"]\n",
        "        in_ch = in_img_ch\n",
        "        if self.use_gabor:\n",
        "            self.gabor = GaborStem(gcfg)\n",
        "            in_ch = in_img_ch + self.gabor.out_channels if gcfg[\"mode\"]==\"concat\" else self.gabor.out_channels\n",
        "\n",
        "        if in_ch == 3:\n",
        "            self.adapter = nn.Identity()\n",
        "        else:\n",
        "            mid_ch = max(16, in_ch // 4)\n",
        "            self.adapter = nn.Sequential(\n",
        "                nn.Conv2d(in_ch, mid_ch, kernel_size=1, bias=False),\n",
        "                nn.BatchNorm2d(mid_ch),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(mid_ch, 3, kernel_size=1, bias=False)\n",
        "            )\n",
        "        self.net = smp.Unet(encoder_name='resnet50', encoder_weights='imagenet',\n",
        "                            in_channels=3, classes=1, activation=None)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_gabor:\n",
        "            g = self.gabor(x)\n",
        "            x = torch.cat([x, g], dim=1) if self.mode==\"concat\" else g\n",
        "        return self.net(self.adapter(x))\n",
        "\n",
        "IMG_SIZE = CFG[\"TRAIN\"][\"img_size\"]; BATCH = CFG[\"TRAIN\"][\"batch_size\"]\n",
        "\n",
        "train_tfms = A.Compose([\n",
        "    A.RandomResizedCrop(IMG_SIZE[0], IMG_SIZE[1], scale=(0.6,1.0), ratio=(0.9,1.1), interpolation=cv2.INTER_LINEAR),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.2),\n",
        "    A.RandomRotate90(p=0.2),\n",
        "    A.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.1, hue=0.02, p=0.3),\n",
        "    A.Normalize(), ToTensorV2(),\n",
        "])\n",
        "val_tfms = A.Compose([A.Resize(IMG_SIZE[0], IMG_SIZE[1], interpolation=cv2.INTER_LINEAR), A.Normalize(), ToTensorV2()])\n",
        "\n",
        "all_imgs = []\n",
        "for ext in ('*.jpg','*.jpeg','*.png','*.tif','*.tiff'):\n",
        "    all_imgs.extend(gglob(os.path.join(IMG_LOCAL, ext)))\n",
        "random.shuffle(all_imgs)\n",
        "\n",
        "train_val, test_paths = train_test_split(all_imgs, test_size=0.2, random_state=SEED)\n",
        "train_paths, val_paths = train_test_split(train_val, test_size=0.15, random_state=SEED)\n",
        "\n",
        "train_ds = SegDataset(train_paths, MSK_LOCAL, size=IMG_SIZE, transform=train_tfms)\n",
        "val_ds   = SegDataset(val_paths,   MSK_LOCAL, size=IMG_SIZE, transform=val_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True,  num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "print(f\"Data ready. Train: {len(train_ds)}, Val: {len(val_ds)}\")\n",
        "\n",
        "SPLIT_DIR = os.path.join(BASE_DRIVE, \"splits\")\n",
        "os.makedirs(SPLIT_DIR, exist_ok=True)\n",
        "with open(os.path.join(SPLIT_DIR, \"train_files.txt\"), \"w\") as f: [f.write(p+\"\\n\") for p in train_paths]\n",
        "with open(os.path.join(SPLIT_DIR, \"val_files.txt\"), \"w\")   as f: [f.write(p+\"\\n\") for p in val_paths]\n",
        "with open(os.path.join(SPLIT_DIR, \"test_files.txt\"), \"w\")  as f: [f.write(p+\"\\n\") for p in test_paths]\n",
        "\n",
        "def dice_loss_binary(logits, y, eps=1e-6):\n",
        "    p = torch.sigmoid(logits)\n",
        "    num = 2*(p*y).sum(dim=(1,2,3)) + eps\n",
        "    den = (p*p).sum(dim=(1,2,3)) + (y*y).sum(dim=(1,2,3)) + eps\n",
        "    return 1 - (num/den).mean()\n",
        "\n",
        "POS_WEIGHT = torch.tensor([CFG[\"TRAIN\"][\"pos_weight\"]], device=DEVICE)\n",
        "bce_w = nn.BCEWithLogitsLoss(pos_weight=POS_WEIGHT)\n",
        "\n",
        "def combined_loss_baseline(logits, y):\n",
        "    return dice_loss_binary(logits, y) + bce_w(logits, y)\n",
        "\n",
        "USE_BOUNDARY = True\n",
        "try:\n",
        "    from lovasz_losses import lovasz_hinge\n",
        "    def boundary_loss(logits, y):\n",
        "        lap = torch.tensor([[0,-1,0],[-1,4,-1],[0,-1,0]], dtype=torch.float32, device=logits.device).view(1,1,3,3)\n",
        "        p = torch.sigmoid(logits)\n",
        "        pe = F.conv2d(p, lap, padding=1); ye = F.conv2d(y, lap, padding=1)\n",
        "        return F.l1_loss(torch.abs(pe), torch.abs(ye))\n",
        "    def combined_loss_lovasz(logits, y):\n",
        "        lh = lovasz_hinge(logits.squeeze(1), y.squeeze(1).float())\n",
        "        dl = dice_loss_binary(logits, y)\n",
        "        if USE_BOUNDARY:\n",
        "            bl = boundary_loss(logits, y); return 0.45*dl + 0.45*lh + 0.10*bl\n",
        "        else:\n",
        "            return 0.5*dl + 0.5*lh\n",
        "except Exception:\n",
        "    def combined_loss_lovasz(*args, **kwargs):\n",
        "        raise RuntimeError(\"LovÃ¡sz not installed. Run pip install line at the top and re-run.\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def pooled_counts_at_thr(loader, model, thr=0.5):\n",
        "    model.eval()\n",
        "    tp=fp=fn=0\n",
        "    for x,y in loader:\n",
        "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
        "        logits = model(x)\n",
        "        p = (torch.sigmoid(logits) > thr).to(y.dtype)\n",
        "        tp += (p*y).sum().item()\n",
        "        fp += (p*(1-y)).sum().item()\n",
        "        fn += ((1-p)*y).sum().item()\n",
        "    return tp, fp, fn\n",
        "\n",
        "def iou_dice(tp, fp, fn, eps=1e-6):\n",
        "    iou  = (tp+eps)/(tp+fp+fn+eps)\n",
        "    dice = (2*tp+eps)/(2*tp+fp+fn+eps)\n",
        "    return float(iou), float(dice)\n",
        "\n",
        "def sweep_thresholds(loader, model, thr_grid=np.linspace(0.2,0.8,13)):\n",
        "    rows=[]; best={\"thr\":None,\"micro_IoU\":-1,\"Dice\":-1}\n",
        "    for thr in thr_grid:\n",
        "        tp,fp,fn = pooled_counts_at_thr(loader, model, float(thr))\n",
        "        iou,dice = iou_dice(tp,fp,fn)\n",
        "        rows.append({\"thr\":float(thr),\"micro_IoU\":iou,\"Dice\":dice,\"tp\":tp,\"fp\":fp,\"fn\":fn})\n",
        "        if iou>best[\"micro_IoU\"]: best={\"thr\":float(thr),\"micro_IoU\":iou,\"Dice\":dice}\n",
        "    return rows, best\n",
        "\n",
        "def make_optimizer(model, base_lr, wd):\n",
        "    param_groups = [\n",
        "        {'params': model.net.encoder.parameters(), 'lr': base_lr / 10.0},\n",
        "        {'params': model.net.decoder.parameters(), 'lr': base_lr},\n",
        "        {'params': model.net.segmentation_head.parameters(), 'lr': base_lr},\n",
        "    ]\n",
        "    if hasattr(model, 'adapter') and not isinstance(model.adapter, nn.Identity):\n",
        "         param_groups.append({'params': model.adapter.parameters(), 'lr': base_lr})\n",
        "    return torch.optim.AdamW(param_groups, lr=base_lr, weight_decay=wd)\n",
        "\n",
        "def make_scheduler(optimizer):\n",
        "    return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
        "\n",
        "def train_epoch(model, loader, optimizer, scaler, loss_fn):\n",
        "    model.train(); tot=0.0; meter=0.0\n",
        "    for x,y in tqdm(loader, desc=\"Train\", leave=False):\n",
        "        x,y = x.to(DEVICE,non_blocking=True), y.to(DEVICE,non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.amp.autocast(device_type='cuda' if DEVICE.type=='cuda' else 'cpu'):\n",
        "            logits = model(x); loss = loss_fn(logits, y)\n",
        "        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
        "        tot += loss.item()\n",
        "        with torch.no_grad():\n",
        "            tp,fp,fn = pooled_counts_at_thr([(x,y)], model, thr=0.5)\n",
        "            iou,_ = iou_dice(tp,fp,fn); meter += iou\n",
        "    return tot/max(1,len(loader)), meter/max(1,len(loader))\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate_epoch(model, loader, loss_fn):\n",
        "    model.eval(); tot=0.0; meter=0.0\n",
        "    for x,y in loader:\n",
        "        x,y = x.to(DEVICE,non_blocking=True), y.to(DEVICE,non_blocking=True)\n",
        "        with torch.amp.autocast(device_type='cuda' if DEVICE.type=='cuda' else 'cpu'):\n",
        "            logits = model(x); loss = loss_fn(logits, y)\n",
        "        tot += loss.item()\n",
        "        tp,fp,fn = pooled_counts_at_thr([(x,y)], model, thr=0.5)\n",
        "        iou,_ = iou_dice(tp,fp,fn); meter += iou\n",
        "    return tot/max(1,len(loader)), meter/max(1,len(loader))\n",
        "\n",
        "def run_training(model, epochs, loss_fn, tag, patience=5):\n",
        "    optimizer = make_optimizer(model, CFG[\"TRAIN\"][\"lr\"], CFG[\"TRAIN\"][\"weight_decay\"])\n",
        "    scheduler = make_scheduler(optimizer)\n",
        "    scaler = torch.amp.GradScaler('cuda' if DEVICE.type=='cuda' else 'cpu')\n",
        "    best_iou = -1.0\n",
        "    best_path = os.path.join(MODELS_DIR, f\"{tag}.pth\")\n",
        "    epochs_no_improve = 0\n",
        "    print(f\"\\nðŸš€ Training: {tag}\")\n",
        "    for ep in range(1, epochs+1):\n",
        "        trL, trI = train_epoch(model, train_loader, optimizer, scaler, loss_fn)\n",
        "        vaL, vaI = validate_epoch(model, val_loader, loss_fn)\n",
        "        scheduler.step(vaI)\n",
        "        print(f\"Epoch {ep}/{epochs} | Train L {trL:.4f} IoU@0.5 {trI:.3f} || Val L {vaL:.4f} IoU@0.5 {vaI:.3f}\")\n",
        "        if vaI > best_iou:\n",
        "            best_iou = vaI\n",
        "            torch.save({\"state_dict\": model.state_dict(),\n",
        "                        \"img_size\": IMG_SIZE, \"gabor_cfg\": CFG[\"GABOR\"]}, best_path)\n",
        "            print(f\"ðŸ’¾ Saved best -> {best_path} (IoU@0.5 {best_iou:.4f})\")\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"ðŸ›‘ Early stopping triggered after {patience} epochs with no improvement.\")\n",
        "            break\n",
        "    return best_path, best_iou, model\n",
        "\n",
        "baseline_tag = f\"UNetRes50_Gabor-{CFG['GABOR']['mode']}_{'learn' if CFG['GABOR']['learnable'] else 'fixed'}\" if CFG[\"GABOR\"][\"enabled\"] else \"UNetRes50_plain\"\n",
        "if CFG[\"RUN\"][\"DO_BASELINE\"]:\n",
        "    base_model = UNetWithGabor(CFG[\"GABOR\"]).to(DEVICE)\n",
        "    best_ckpt, best_iou, base_model = run_training(base_model, CFG[\"TRAIN\"][\"epochs\"], combined_loss_baseline, baseline_tag)\n",
        "    rows, best = sweep_thresholds(val_loader, base_model)\n",
        "    print(\"\\n=== Baseline sweep ===\")\n",
        "    for r in rows: print(f\"thr={r['thr']:.2f}  micro_IoU={r['micro_IoU']:.4f}  Dice={r['Dice']:.4f}\")\n",
        "    print(f\"BEST @ thr={best['thr']:.2f} | micro_IoU={best['micro_IoU']:.4f} Dice={best['Dice']:.4f}\")\n",
        "\n",
        "if CFG[\"RUN\"][\"DO_LOVASZ\"]:\n",
        "    if not 'base_model' in locals():\n",
        "        base_model = UNetWithGabor(CFG[\"GABOR\"]).to(DEVICE)\n",
        "        sd = torch.load(os.path.join(MODELS_DIR, baseline_tag+\".pth\"), map_location=DEVICE)[\"state_dict\"]\n",
        "        base_model.load_state_dict(sd, strict=True)\n",
        "    lovasz_tag = baseline_tag + \"_lovasz\"\n",
        "    best_ckpt_l, best_iou_l, base_model = run_training(base_model, 10, combined_loss_lovasz, lovasz_tag)\n",
        "    rows, best = sweep_thresholds(val_loader, base_model)\n",
        "    print(\"\\n=== LovÃ¡sz sweep ===\")\n",
        "    for r in rows: print(f\"thr={r['thr']:.2f}  micro_IoU={r['micro_IoU']:.4f}  Dice={r['Dice']:.4f}\")\n",
        "    print(f\"BEST @ thr={best['thr']:.2f} | micro_IoU={best['micro_IoU']:.4f} Dice={best['Dice']:.4f}\")\n",
        "\n",
        "adapter_tag = \"UNetRes50_GaborAdapter_imagenet\" if CFG[\"GABOR\"][\"enabled\"] else \"UNetRes50_Adapter_imagenet\"\n",
        "if CFG[\"RUN\"][\"DO_ADAPTER_VARIANT\"]:\n",
        "    adapter_model = UNetWithGabor_Adapted(CFG[\"GABOR\"]).to(DEVICE)\n",
        "    best_ckpt_ad, best_iou_ad, adapter_model = run_training(adapter_model, CFG[\"TRAIN\"][\"adapter_epochs\"], combined_loss_baseline, adapter_tag)\n",
        "    rows, best_ad = sweep_thresholds(val_loader, adapter_model)\n",
        "    print(\"\\n=== Adapter sweep ===\")\n",
        "    for r in rows: print(f\"thr={r['thr']:.2f}  micro_IoU={r['micro_IoU']:.4f}  Dice={r['Dice']:.4f}\")\n",
        "    print(f\"BEST @ thr={best_ad['thr']:.2f} | micro_IoU={best_ad['micro_IoU']:.4f} Dice={best_ad['Dice']:.4f}\")\n",
        "\n",
        "EXP_NAME = adapter_tag if CFG[\"RUN\"][\"DO_ADAPTER_VARIANT\"] else (lovasz_tag if CFG[\"RUN\"][\"DO_LOVASZ\"] else baseline_tag)\n",
        "OUT = os.path.join(EXPORTS_DIR, EXP_NAME, datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "os.makedirs(OUT, exist_ok=True)\n",
        "\n",
        "active_model = adapter_model if CFG[\"RUN\"][\"DO_ADAPTER_VARIANT\"] else (base_model)\n",
        "\n",
        "torch.save({\n",
        "    \"state_dict\": active_model.state_dict(),\n",
        "    \"gabor_cfg\": CFG[\"GABOR\"],\n",
        "    \"img_size\": IMG_SIZE,\n",
        "    \"exp_name\": EXP_NAME\n",
        "}, os.path.join(OUT, \"checkpoint_full.pth\"))\n",
        "torch.save(active_model.state_dict(), os.path.join(OUT, \"weights_only.pth\"))\n",
        "\n",
        "thr_grid = np.linspace(0.2,0.8,13)\n",
        "rows, best = sweep_thresholds(val_loader, active_model, thr_grid)\n",
        "with open(os.path.join(OUT, \"val_threshold_sweep.csv\"), \"w\", newline=\"\") as f:\n",
        "    w = csv.DictWriter(f, fieldnames=list(rows[0].keys())); w.writeheader(); w.writerows(rows)\n",
        "with open(os.path.join(OUT, \"summary.json\"), \"w\") as f:\n",
        "    json.dump({\"exp\": EXP_NAME, \"best\": best, \"img_size\": IMG_SIZE, \"gabor_cfg\": CFG[\"GABOR\"], \"device\": str(DEVICE)}, f, indent=2)\n",
        "\n",
        "!pip freeze > \"{OUT}/pip-freeze.txt\"\n",
        "\n",
        "try:\n",
        "    active_model.eval()\n",
        "    H,W = IMG_SIZE\n",
        "    example = torch.randn(1,3,H,W, device=DEVICE)\n",
        "    torch.jit.trace(active_model, example, strict=False).save(os.path.join(OUT, \"model_traced.pt\"))\n",
        "    torch.onnx.export(\n",
        "        active_model, example, os.path.join(OUT, \"model.onnx\"),\n",
        "        input_names=[\"image\"], output_names=[\"logits\"], opset_version=17,\n",
        "        dynamic_axes={\"image\":{0:\"N\",2:\"H\",3:\"W\"}, \"logits\":{0:\"N\",2:\"H\",3:\"W\"}}\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(\"[Export skipped]\", e)\n",
        "\n",
        "try:\n",
        "    import torchvision\n",
        "    SAMPLE_OUT = os.path.join(OUT, \"preds_val_samples\"); os.makedirs(SAMPLE_OUT, exist_ok=True)\n",
        "    best_thr = float(best[\"thr\"])\n",
        "    active_model.eval(); saved=0\n",
        "    with torch.no_grad():\n",
        "        for i,(x,y) in enumerate(val_loader):\n",
        "            logits = active_model(x.to(DEVICE))\n",
        "            pm = (torch.sigmoid(logits) > best_thr).float().cpu()\n",
        "            for b in range(min(pm.size(0), 4)):\n",
        "                torchvision.utils.save_image(pm[b], os.path.join(SAMPLE_OUT, f\"val_{i:04d}_{b:02d}.png\"))\n",
        "                saved += 1\n",
        "                if saved >= CFG[\"RUN\"][\"SAVE_SAMPLES\"]: break\n",
        "            if saved >= CFG[\"RUN\"][\"SAVE_SAMPLES\"]: break\n",
        "except Exception as e:\n",
        "    print(\"[Sample export skipped]\", e)\n",
        "\n",
        "with open(os.path.join(OUT, \"CFG.json\"), \"w\") as f: json.dump(CFG, f, indent=2, default=str)\n",
        "for split_name, split_list in [(\"train_files.txt\", train_paths), (\"val_files.txt\", val_paths), (\"test_files.txt\", test_paths)]:\n",
        "    with open(os.path.join(OUT, split_name), \"w\") as f:\n",
        "        for p in split_list: f.write(p+\"\\n\")\n",
        "\n",
        "def sha256(p):\n",
        "    h=hashlib.sha256()\n",
        "    with open(p,'rb') as f:\n",
        "        for chunk in iter(lambda: f.read(1<<20), b''): h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "artifacts = [\"checkpoint_full.pth\",\"weights_only.pth\",\"val_threshold_sweep.csv\",\"summary.json\"]\n",
        "hashes = {a: sha256(os.path.join(OUT,a)) for a in artifacts if os.path.exists(os.path.join(OUT,a))}\n",
        "with open(os.path.join(OUT,\"sha256.json\"),\"w\") as f: json.dump(hashes,f,indent=2)\n",
        "\n",
        "print(\"\\nâœ… Export saved to:\", OUT)\n",
        "print(\"ðŸ” Hashes:\", hashes)"
      ],
      "metadata": {
        "id": "gTxmbYzp8n0M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}